# Smart Business - Robots.txt
# This file tells search engines which pages to crawl

User-agent: *
Allow: /

# Disallow admin or private areas (if any in future)
# Disallow: /admin/
# Disallow: /private/

# Allow all CSS, JS, and images for proper rendering
Allow: /css/
Allow: /js/
Allow: /images/

# Sitemap location
Sitemap: https://www.smartbusiness-eg.com/sitemap.xml

# Crawl-delay (optional - helps prevent server overload)
Crawl-delay: 1
